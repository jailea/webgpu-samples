(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[118],{5671:function(e,n,t){"use strict";t.d(n,{Tl:function(){return p},hu:function(){return d}});var r=t(5893),a=t(9008),i=t.n(a),o=t(1163),s=t(7294),l=t(9147),u=t.n(l);t(7319);let c=e=>{let n=(0,s.useRef)(null),a=(0,s.useMemo)(()=>e.sources.map(e=>{let{name:n,contents:a}=e;return{name:n,...function(e){let n;let a=null;{a=document.createElement("div");let i=t(4631);n=i(a,{lineNumbers:!0,lineWrapping:!0,theme:"monokai",readOnly:!0})}return{Container:function(t){return(0,r.jsx)("div",{...t,children:(0,r.jsx)("div",{ref(t){a&&t&&(t.appendChild(a),n.setOption("value",e))}})})}}}(a)}}),e.sources),l=(0,s.useRef)(null),c=(0,s.useMemo)(()=>{if(e.gui){let n=t(4376),r=new n.GUI({autoPlace:!1});return r.domElement.style.position="relative",r.domElement.style.zIndex="1000",r}},[]),p=(0,s.useRef)(null),d=(0,s.useMemo)(()=>{if(e.stats){let n=t(2792);return new n}},[]),m=(0,o.useRouter)(),f=m.asPath.match(/#([a-zA-Z0-9\.\/]+)/),[g,h]=(0,s.useState)(null),[x,b]=(0,s.useState)(null);return(0,s.useEffect)(()=>{if(f?b(f[1]):b(a[0].name),c&&l.current)for(l.current.appendChild(c.domElement);c.__controllers.length>0;)c.__controllers[0].remove();d&&p.current&&(d.dom.style.position="absolute",d.showPanel(1),p.current.appendChild(d.dom));let t={active:!0},r=()=>{t.active=!1};try{let i=n.current;if(!i)throw Error("The canvas is not available");let o=e.init({canvas:i,pageState:t,gui:c,stats:d});o instanceof Promise&&o.catch(e=>{console.error(e),h(e)})}catch(s){console.error(s),h(s)}return r},[]),(0,r.jsxs)("main",{children:[(0,r.jsxs)(i(),{children:[(0,r.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),(0,r.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),(0,r.jsx)("meta",{name:"description",content:e.description}),(0,r.jsx)("meta",{httpEquiv:"origin-trial",content:e.originTrial})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h1",{children:e.name}),(0,r.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/".concat("Cryszzz/webgpu-samples","/tree/main/").concat(e.filename),children:"See it on Github!"}),(0,r.jsx)("p",{children:e.description}),g?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("p",{children:"Something went wrong. Do your browser and device support WebGPU?"}),(0,r.jsx)("p",{children:"".concat(g)})]}):null]}),(0,r.jsxs)("div",{className:u().canvasContainer,children:[(0,r.jsx)("div",{style:{position:"absolute",left:10},ref:p}),(0,r.jsx)("div",{style:{position:"absolute",right:10},ref:l}),(0,r.jsx)("canvas",{ref:n})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("nav",{className:u().sourceFileNav,children:(0,r.jsx)("ul",{children:a.map((e,n)=>(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"#".concat(e.name),"data-active":x==e.name,onClick(){b(e.name)},children:e.name})},n))})}),a.map((e,n)=>(0,r.jsx)(e.Container,{className:u().sourceFileContainer,"data-active":x==e.name},n))]})]})},p=e=>(0,r.jsx)(c,{...e});function d(e,n){if(!e)throw Error(n)}},7118:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return x}});var r,a,i=t(6416),o=t(5671),s="\nconst modeAlbedoTexture = 0;\nconst modeNormalTexture = 1;\nconst modeDepthTexture = 2;\nconst modeNormalMap = 3;\nconst modeParallaxScale = 4;\nconst modeSteepParallax = 5;\n\nstruct SpaceTransforms {\n  worldViewProjMatrix: mat4x4f,\n  worldViewMatrix: mat4x4f,\n}\n\nstruct MapInfo {\n  lightPosVS: vec3f, // Light position in view space\n  mode: u32,\n  lightIntensity: f32,\n  depthScale: f32,\n  depthLayers: f32,\n}\n\nstruct VertexInput {\n  // Shader assumes the missing 4th float is 1.0\n  @location(0) position : vec4f,\n  @location(1) normal : vec3f,\n  @location(2) uv : vec2f,\n  @location(3) vert_tan: vec3f,\n  @location(4) vert_bitan: vec3f,\n}\n\nstruct VertexOutput {\n  @builtin(position) posCS : vec4f,    // vertex position in clip space\n  @location(0) posVS : vec3f,          // vertex position in view space\n  @location(1) tangentVS: vec3f,       // vertex tangent in view space\n  @location(2) bitangentVS: vec3f,     // vertex tangent in view space\n  @location(3) normalVS: vec3f,        // vertex normal in view space\n  @location(5) uv : vec2f,             // vertex texture coordinate\n}\n\n// Uniforms\n@group(0) @binding(0) var<uniform> spaceTransform : SpaceTransforms;\n@group(0) @binding(1) var<uniform> mapInfo: MapInfo;\n\n// Texture info\n@group(1) @binding(0) var textureSampler: sampler;\n@group(1) @binding(1) var albedoTexture: texture_2d<f32>;\n@group(1) @binding(2) var normalTexture: texture_2d<f32>;\n@group(1) @binding(3) var depthTexture: texture_2d<f32>;\n\n\n@vertex\nfn vertexMain(input: VertexInput) -> VertexOutput {\n  var output : VertexOutput;\n\n  output.posCS = spaceTransform.worldViewProjMatrix * input.position;\n  output.posVS = (spaceTransform.worldViewMatrix * input.position).xyz;\n  output.tangentVS = (spaceTransform.worldViewMatrix * vec4(input.vert_tan, 0)).xyz;\n  output.bitangentVS = (spaceTransform.worldViewMatrix * vec4(input.vert_bitan, 0)).xyz;\n  output.normalVS = (spaceTransform.worldViewMatrix * vec4(input.normal, 0)).xyz;\n  output.uv = input.uv;\n\n  return output;\n}\n\n@fragment\nfn fragmentMain(input: VertexOutput) -> @location(0) vec4f {\n  // Build the matrix to convert from tangent space to view space\n  let tangentToView = mat3x3f(\n    input.tangentVS,\n    input.bitangentVS,\n    input.normalVS,\n  );\n\n  // The inverse of a non-scaling affine 3x3 matrix is it's transpose\n  let viewToTangent = transpose(tangentToView);\n\n  // Calculate the normalized vector in tangent space from the camera to the fragment\n  let viewDirTS = normalize(viewToTangent * input.posVS);\n\n  // Apply parallax to the texture coordinate, if parallax is enabled\n  var uv : vec2f;\n  switch (mapInfo.mode) {\n    case modeParallaxScale: {\n      uv = parallaxScale(input.uv, viewDirTS);\n      break;\n    }\n    case modeSteepParallax: {\n      uv = parallaxSteep(input.uv, viewDirTS);\n      break;\n    }\n    default: {\n      uv = input.uv;\n      break;\n    }\n  }\n\n  // Sample the albedo texture\n  let albedoSample = textureSample(albedoTexture, textureSampler, uv);\n\n  // Sample the normal texture\n  let normalSample = textureSample(normalTexture, textureSampler, uv);\n\n  switch (mapInfo.mode) {\n    case modeAlbedoTexture: { // Output the albedo sample\n      return albedoSample;\n    }\n    case modeNormalTexture: { // Output the normal sample\n      return normalSample;\n    }\n    case modeDepthTexture: { // Output the depth map\n      return textureSample(depthTexture, textureSampler, input.uv);\n    }\n    default: {\n      // Transform the normal sample to a tangent space normal\n      let normalTS = normalSample.xyz * 2 - 1;\n\n      // Convert normal from tangent space to view space, and normalize\n      let normalVS = normalize(tangentToView * normalTS);\n\n      // Calculate the vector in view space from the light position to the fragment\n      let fragToLightVS = mapInfo.lightPosVS - input.posVS;\n\n      // Calculate the square distance from the light to the fragment\n      let lightSqrDist = dot(fragToLightVS, fragToLightVS);\n\n      // Calculate the normalized vector in view space from the fragment to the light\n      let lightDirVS = fragToLightVS * inverseSqrt(lightSqrDist);\n\n      // Light strength is inversely proportional to square of distance from light\n      let diffuseLight = mapInfo.lightIntensity * max(dot(lightDirVS, normalVS), 0) / lightSqrDist;\n\n      // The diffuse is the albedo color multiplied by the diffuseLight\n      let diffuse = albedoSample.rgb * diffuseLight;\n\n      return vec4f(diffuse, 1.0);\n    }\n  }\n}\n\n\n// Returns the uv coordinate displaced in the view direction by a magnitude calculated by the depth\n// sampled from the depthTexture and the angle between the surface normal and view direction.\nfn parallaxScale(uv: vec2f, viewDirTS: vec3f) -> vec2f {\n  let depthSample = textureSample(depthTexture, textureSampler, uv).r;\n  return uv + viewDirTS.xy * (depthSample * mapInfo.depthScale) / -viewDirTS.z;\n}\n\n// Returns the uv coordinates displaced in the view direction by ray-tracing the depth map.\nfn parallaxSteep(startUV: vec2f, viewDirTS: vec3f) -> vec2f {\n  // Calculate derivatives of the texture coordinate, so we can sample the texture with non-uniform\n  // control flow.\n  let ddx = dpdx(startUV);\n  let ddy = dpdy(startUV);\n\n  // Calculate the delta step in UV and depth per iteration\n  let uvDelta = viewDirTS.xy * mapInfo.depthScale / (-viewDirTS.z * mapInfo.depthLayers);\n  let depthDelta = 1.0 / f32(mapInfo.depthLayers);\n  let posDelta = vec3(uvDelta, depthDelta);\n\n  // Walk the depth texture, and stop when the ray intersects the depth map\n  var pos = vec3(startUV, 0);\n  for (var i = 0; i < 32; i++) {\n    if (pos.z >= textureSampleGrad(depthTexture, textureSampler, pos.xy, ddx, ddy).r) {\n      break; // Hit the surface\n    }\n    pos += posDelta;\n  }\n\n  return pos.xy;\n}\n";let l=function(e,n){let t=arguments.length>2&&void 0!==arguments[2]&&arguments[2],r=arguments.length>3&&void 0!==arguments[3]&&arguments[3],a=t?GPUBufferUsage.VERTEX|GPUBufferUsage.STORAGE:GPUBufferUsage.VERTEX,i=r?GPUBufferUsage.INDEX|GPUBufferUsage.STORAGE:GPUBufferUsage.INDEX,o=e.createBuffer({size:n.vertices.byteLength,usage:a,mappedAtCreation:!0});new Float32Array(o.getMappedRange()).set(n.vertices),o.unmap();let s=e.createBuffer({size:n.indices.byteLength,usage:i,mappedAtCreation:!0});return n.indices.byteLength===n.indices.length*Uint16Array.BYTES_PER_ELEMENT?new Uint16Array(s.getMappedRange()).set(n.indices):new Uint32Array(s.getMappedRange()).set(n.indices),s.unmap(),{vertexBuffer:o,indexBuffer:s,indexCount:n.indices.length}},u=(e,n,t,r,a,i,o)=>{let s=[];for(let l=0;l<e.length;l++)s.push({binding:e[l],visibility:n[l%n.length],[t[l]]:r[l]});let u=o.createBindGroupLayout({label:"".concat(i,".bindGroupLayout"),entries:s}),c=[];for(let p=0;p<a.length;p++){let d=[];for(let m=0;m<a[0].length;m++)d.push({binding:m,resource:a[p][m]});let f=o.createBindGroup({label:"".concat(i,".bindGroup").concat(p),layout:u,entries:d});c.push(f)}return{bindGroups:c,bindGroupLayout:u}},c=e=>{let n=e.split("x"),t=parseInt(n[0].replace(/[^0-9]/g,""))/8,r=t*(void 0!==n[1]?parseInt(n[1]):1);return r},p=e=>{let n=e.reduce((e,n,t)=>{let r={shaderLocation:t,offset:e.arrayStride,format:n},a=e.arrayStride+c(n),i={attributes:[...e.attributes,r],arrayStride:a};return i},{attributes:[],arrayStride:0}),t={arrayStride:n.arrayStride,attributes:n.attributes};return t},d=function(e,n,t,r,a,i,o){let s=arguments.length>7&&void 0!==arguments[7]&&arguments[7],l=arguments.length>8&&void 0!==arguments[8]?arguments[8]:"triangle-list",u=arguments.length>9&&void 0!==arguments[9]?arguments[9]:"back",c={label:"".concat(n,".pipeline"),layout:e.createPipelineLayout({label:"".concat(n,".pipelineLayout"),bindGroupLayouts:t}),vertex:{module:e.createShaderModule({label:"".concat(n,".vertexShader"),code:r}),entryPoint:"vertexMain",buffers:0!==a.length?[p(a)]:[]},fragment:{module:e.createShaderModule({label:"".concat(n,".fragmentShader"),code:i}),entryPoint:"fragmentMain",targets:[{format:o}]},primitive:{topology:l,cullMode:u}};return s&&(c.depthStencil={depthCompare:"less",depthWriteEnabled:!0,format:"depth24plus"}),e.createRenderPipeline(c)},m=(e,n)=>{let t=e.createTexture({size:[n.width,n.height,1],format:"rgba8unorm",usage:GPUTextureUsage.TEXTURE_BINDING|GPUTextureUsage.COPY_DST|GPUTextureUsage.RENDER_ATTACHMENT});return e.queue.copyExternalImageToTexture({source:n},{texture:t},[n.width,n.height]),t};var f="src/sample/normalMap/main.ts";(r=a||(a={}))[r.Spiral=0]="Spiral",r[r.Toybox=1]="Toybox",r[r.BrickWall=2]="BrickWall";let g=async e=>{let n,t,r,o,c,p,f,g,{canvas:h,pageState:x,gui:b}=e,v=await navigator.gpu.requestAdapter(),w=await v.requestDevice();if(!x.active)return;let y=h.getContext("webgpu"),T=window.devicePixelRatio;h.width=h.clientWidth*T,h.height=h.clientHeight*T;let S=navigator.gpu.getPreferredCanvasFormat();y.configure({device:w,format:S,alphaMode:"premultiplied"});let P={"Bump Mode":"Normal Map",cameraPosX:0,cameraPosY:.8,cameraPosZ:-1.4,lightPosX:1.7,lightPosY:.7,lightPosZ:-1.9,lightIntensity:5,depthScale:.05,depthLayers:16,Texture:"Spiral","Reset Light"(){}},B=w.createTexture({size:[h.width,h.height],format:"depth24plus",usage:GPUTextureUsage.RENDER_ATTACHMENT}),G=w.createBuffer({size:256,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),U=w.createBuffer({size:8*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),V=new ArrayBuffer(U.size),M=new DataView(V,0,V.byteLength);{let E=await fetch("../assets/img/wood_albedo.png"),I=await createImageBitmap(await E.blob());n=m(w,I)}{let A=await fetch("../assets/img/spiral_normal.png"),_=await createImageBitmap(await A.blob());t=m(w,_)}{let F=await fetch("../assets/img/spiral_height.png"),L=await createImageBitmap(await F.blob());r=m(w,L)}{let C=await fetch("../assets/img/toybox_normal.png"),D=await createImageBitmap(await C.blob());o=m(w,D)}{let R=await fetch("../assets/img/toybox_height.png"),N=await createImageBitmap(await R.blob());c=m(w,N)}{let O=await fetch("../assets/img/brickwall_albedo.png"),j=await createImageBitmap(await O.blob());p=m(w,j)}{let z=await fetch("../assets/img/brickwall_normal.png"),X=await createImageBitmap(await z.blob());f=m(w,X)}{let k=await fetch("../assets/img/brickwall_height.png"),Y=await createImageBitmap(await k.blob());g=m(w,Y)}let q=w.createSampler({magFilter:"linear",minFilter:"linear"}),Z={colorAttachments:[{view:void 0,clearValue:{r:0,g:0,b:0,a:1},loadOp:"clear",storeOp:"store"}],depthStencilAttachment:{view:B.createView(),depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store"}},W=l(w,function(e,n,t){let r=[{tangent:5,bitangent:2,normal:0},{tangent:4,bitangent:2,normal:1},{tangent:0,bitangent:5,normal:2},{tangent:0,bitangent:4,normal:3},{tangent:0,bitangent:2,normal:4},{tangent:1,bitangent:2,normal:5}],a=new Float32Array(56*r.length),i=new Uint16Array(6*r.length),o=[[+e/2,0,0],[-e/2,0,0],[0,+n/2,0],[0,-n/2,0],[0,0,+t/2],[0,0,-t/2]],s=0,l=0;for(let u=0;u<r.length;u++){let c=r[u],p=o[c.tangent],d=o[c.bitangent],m=o[c.normal];for(let f=0;f<2;f++)for(let g=0;g<2;g++){for(let h=0;h<3;h++)a[s++]=m[h]+(0==f?-1:1)*p[h]+(0==g?-1:1)*d[h];for(let x=0;x<3;x++)a[s++]=m[x];a[s++]=f,a[s++]=g;for(let b=0;b<3;b++)a[s++]=p[b];for(let v=0;v<3;v++)a[s++]=d[v]}i[l++]=4*u+0,i[l++]=4*u+2,i[l++]=4*u+1,i[l++]=4*u+2,i[l++]=4*u+3,i[l++]=4*u+1}return{vertices:a,indices:i,vertexStride:56}}(1,1,1)),H=u([0,1],[GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,GPUShaderStage.FRAGMENT|GPUShaderStage.VERTEX],["buffer","buffer"],[{type:"uniform"},{type:"uniform"}],[[{buffer:G},{buffer:U}]],"Frame",w),$=u([0,1,2,3],[GPUShaderStage.FRAGMENT],["sampler","texture","texture","texture"],[{type:"filtering"},{sampleType:"float"},{sampleType:"float"},{sampleType:"float"}],[[q,n.createView(),t.createView(),r.createView()],[q,n.createView(),o.createView(),c.createView()],[q,p.createView(),f.createView(),g.createView()]],"Surface",w),K=h.width/h.height,J=i._E.perspective(2*Math.PI/5,K,.1,10),Q=()=>{switch(P["Bump Mode"]){case"Albedo Texture":return 0;case"Normal Texture":return 1;case"Depth Texture":return 2;case"Normal Map":return 3;case"Parallax Scale":return 4;case"Steep Parallax":return 5}},ee=d(w,"NormalMappingRender",[H.bindGroupLayout,$.bindGroupLayout],s,["float32x3","float32x3","float32x2","float32x3","float32x3"],s,S,!0),en=0,et=()=>{en=a[P.Texture]};b.add(P,"Bump Mode",["Albedo Texture","Normal Texture","Depth Texture","Normal Map","Parallax Scale","Steep Parallax"]),b.add(P,"Texture",["Spiral","Toybox","BrickWall"]).onChange(et);let er=b.addFolder("Light"),ea=b.addFolder("Depth");er.add(P,"Reset Light").onChange(()=>{ei.setValue(1.7),eo.setValue(.7),es.setValue(-1.9),el.setValue(5)});let ei=er.add(P,"lightPosX",-5,5).step(.1),eo=er.add(P,"lightPosY",-5,5).step(.1),es=er.add(P,"lightPosZ",-5,5).step(.1),el=er.add(P,"lightIntensity",0,10).step(.1);ea.add(P,"depthScale",0,.1).step(.01),ea.add(P,"depthLayers",1,32).step(1),requestAnimationFrame(function e(){if(!x.active)return;let n=i._E.lookAt([P.cameraPosX,P.cameraPosY,P.cameraPosZ],[0,0,0],[0,1,0]),t=i._E.mul(n,function(){let e=i._E.create();i._E.identity(e);let n=Date.now()/1e3;return i._E.rotateY(e,-.5*n,e),e}()),r=i._E.mul(J,t),a=new Float32Array([...r,...t]),o=i.R3.create(P.lightPosX,P.lightPosY,P.lightPosZ),s=i.R3.transformMat4(o,n),l=Q();w.queue.writeBuffer(G,0,a.buffer,a.byteOffset,a.byteLength),M.setFloat32(0,s[0],!0),M.setFloat32(4,s[1],!0),M.setFloat32(8,s[2],!0),M.setUint32(12,l,!0),M.setFloat32(16,P.lightIntensity,!0),M.setFloat32(20,P.depthScale,!0),M.setFloat32(24,P.depthLayers,!0),w.queue.writeBuffer(U,0,V),Z.colorAttachments[0].view=y.getCurrentTexture().createView();let u=w.createCommandEncoder(),c=u.beginRenderPass(Z);c.setPipeline(ee),c.setBindGroup(0,H.bindGroups[0]),c.setBindGroup(1,$.bindGroups[en]),c.setVertexBuffer(0,W.vertexBuffer),c.setIndexBuffer(W.indexBuffer,"uint16"),c.drawIndexed(W.indexCount),c.end(),w.queue.submit([u.finish()]),requestAnimationFrame(e)})},h=()=>(0,o.Tl)({name:"Normal Mapping",description:"This example demonstrates multiple different methods that employ fragment shaders to achieve additional perceptual depth on the surface of a cube mesh. Demonstrated methods include normal mapping, parallax mapping, and steep parallax mapping.",gui:!0,init:g,sources:[{name:f.substring(21),contents:"import { mat4, vec3 } from 'wgpu-matrix';\nimport { makeSample, SampleInit } from '../../components/SampleLayout';\nimport normalMapWGSL from './normalMap.wgsl';\nimport { createMeshRenderable } from '../../meshes/mesh';\nimport { createBoxMeshWithTangents } from '../../meshes/box';\nimport {\n  createBindGroupDescriptor,\n  create3DRenderPipeline,\n  createTextureFromImage,\n} from './utils';\n\nconst MAT4X4_BYTES = 64;\nenum TextureAtlas {\n  Spiral,\n  Toybox,\n  BrickWall,\n}\n\nconst init: SampleInit = async ({ canvas, pageState, gui }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n  if (!pageState.active) return;\n  const context = canvas.getContext('webgpu') as GPUCanvasContext;\n  const devicePixelRatio = window.devicePixelRatio;\n  canvas.width = canvas.clientWidth * devicePixelRatio;\n  canvas.height = canvas.clientHeight * devicePixelRatio;\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n  context.configure({\n    device,\n    format: presentationFormat,\n    alphaMode: 'premultiplied',\n  });\n\n  interface GUISettings {\n    'Bump Mode':\n      | 'Albedo Texture'\n      | 'Normal Texture'\n      | 'Depth Texture'\n      | 'Normal Map'\n      | 'Parallax Scale'\n      | 'Steep Parallax';\n    cameraPosX: number;\n    cameraPosY: number;\n    cameraPosZ: number;\n    lightPosX: number;\n    lightPosY: number;\n    lightPosZ: number;\n    lightIntensity: number;\n    depthScale: number;\n    depthLayers: number;\n    Texture: string;\n    'Reset Light': () => void;\n  }\n\n  const settings: GUISettings = {\n    'Bump Mode': 'Normal Map',\n    cameraPosX: 0.0,\n    cameraPosY: 0.8,\n    cameraPosZ: -1.4,\n    lightPosX: 1.7,\n    lightPosY: 0.7,\n    lightPosZ: -1.9,\n    lightIntensity: 5.0,\n    depthScale: 0.05,\n    depthLayers: 16,\n    Texture: 'Spiral',\n    'Reset Light': () => {\n      return;\n    },\n  };\n\n  // Create normal mapping resources and pipeline\n  const depthTexture = device.createTexture({\n    size: [canvas.width, canvas.height],\n    format: 'depth24plus',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const spaceTransformsBuffer = device.createBuffer({\n    // Buffer holding projection, view, and model matrices plus padding bytes\n    size: MAT4X4_BYTES * 4,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const mapInfoBuffer = device.createBuffer({\n    // Buffer holding mapping type, light uniforms, and depth uniforms\n    size: Float32Array.BYTES_PER_ELEMENT * 8,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n  const mapInfoArray = new ArrayBuffer(mapInfoBuffer.size);\n  const mapInfoView = new DataView(mapInfoArray, 0, mapInfoArray.byteLength);\n\n  // Fetch the image and upload it into a GPUTexture.\n  let woodAlbedoTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/wood_albedo.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    woodAlbedoTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let spiralNormalTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/spiral_normal.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    spiralNormalTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let spiralHeightTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/spiral_height.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    spiralHeightTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let toyboxNormalTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/toybox_normal.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    toyboxNormalTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let toyboxHeightTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/toybox_height.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    toyboxHeightTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let brickwallAlbedoTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/brickwall_albedo.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    brickwallAlbedoTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let brickwallNormalTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/brickwall_normal.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    brickwallNormalTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  let brickwallHeightTexture: GPUTexture;\n  {\n    const response = await fetch('../assets/img/brickwall_height.png');\n    const imageBitmap = await createImageBitmap(await response.blob());\n    brickwallHeightTexture = createTextureFromImage(device, imageBitmap);\n  }\n\n  // Create a sampler with linear filtering for smooth interpolation.\n  const sampler = device.createSampler({\n    magFilter: 'linear',\n    minFilter: 'linear',\n  });\n\n  const renderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        view: undefined, // Assigned later\n\n        clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n    },\n  };\n\n  const box = createMeshRenderable(\n    device,\n    createBoxMeshWithTangents(1.0, 1.0, 1.0)\n  );\n\n  // Uniform bindGroups and bindGroupLayout\n  const frameBGDescriptor = createBindGroupDescriptor(\n    [0, 1],\n    [\n      GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n      GPUShaderStage.FRAGMENT | GPUShaderStage.VERTEX,\n    ],\n    ['buffer', 'buffer'],\n    [{ type: 'uniform' }, { type: 'uniform' }],\n    [[{ buffer: spaceTransformsBuffer }, { buffer: mapInfoBuffer }]],\n    'Frame',\n    device\n  );\n\n  // Texture bindGroups and bindGroupLayout\n  const surfaceBGDescriptor = createBindGroupDescriptor(\n    [0, 1, 2, 3],\n    [GPUShaderStage.FRAGMENT],\n    ['sampler', 'texture', 'texture', 'texture'],\n    [\n      { type: 'filtering' },\n      { sampleType: 'float' },\n      { sampleType: 'float' },\n      { sampleType: 'float' },\n    ],\n    // Multiple bindgroups that accord to the layout defined above\n    [\n      [\n        sampler,\n        woodAlbedoTexture.createView(),\n        spiralNormalTexture.createView(),\n        spiralHeightTexture.createView(),\n      ],\n      [\n        sampler,\n        woodAlbedoTexture.createView(),\n        toyboxNormalTexture.createView(),\n        toyboxHeightTexture.createView(),\n      ],\n      [\n        sampler,\n        brickwallAlbedoTexture.createView(),\n        brickwallNormalTexture.createView(),\n        brickwallHeightTexture.createView(),\n      ],\n    ],\n    'Surface',\n    device\n  );\n\n  const aspect = canvas.width / canvas.height;\n  const projectionMatrix = mat4.perspective(\n    (2 * Math.PI) / 5,\n    aspect,\n    0.1,\n    10.0\n  ) as Float32Array;\n\n  function getViewMatrix() {\n    return mat4.lookAt(\n      [settings.cameraPosX, settings.cameraPosY, settings.cameraPosZ],\n      [0, 0, 0],\n      [0, 1, 0]\n    );\n  }\n\n  function getModelMatrix() {\n    const modelMatrix = mat4.create();\n    mat4.identity(modelMatrix);\n    const now = Date.now() / 1000;\n    mat4.rotateY(modelMatrix, now * -0.5, modelMatrix);\n    return modelMatrix;\n  }\n\n  // Change the model mapping type\n  const getMode = (): number => {\n    switch (settings['Bump Mode']) {\n      case 'Albedo Texture':\n        return 0;\n      case 'Normal Texture':\n        return 1;\n      case 'Depth Texture':\n        return 2;\n      case 'Normal Map':\n        return 3;\n      case 'Parallax Scale':\n        return 4;\n      case 'Steep Parallax':\n        return 5;\n    }\n  };\n\n  const texturedCubePipeline = create3DRenderPipeline(\n    device,\n    'NormalMappingRender',\n    [frameBGDescriptor.bindGroupLayout, surfaceBGDescriptor.bindGroupLayout],\n    normalMapWGSL,\n    // Position,   normal       uv           tangent      bitangent\n    ['float32x3', 'float32x3', 'float32x2', 'float32x3', 'float32x3'],\n    normalMapWGSL,\n    presentationFormat,\n    true\n  );\n\n  let currentSurfaceBindGroup = 0;\n  const onChangeTexture = () => {\n    currentSurfaceBindGroup = TextureAtlas[settings.Texture];\n  };\n\n  gui.add(settings, 'Bump Mode', [\n    'Albedo Texture',\n    'Normal Texture',\n    'Depth Texture',\n    'Normal Map',\n    'Parallax Scale',\n    'Steep Parallax',\n  ]);\n  gui\n    .add(settings, 'Texture', ['Spiral', 'Toybox', 'BrickWall'])\n    .onChange(onChangeTexture);\n  const lightFolder = gui.addFolder('Light');\n  const depthFolder = gui.addFolder('Depth');\n  lightFolder.add(settings, 'Reset Light').onChange(() => {\n    lightPosXController.setValue(1.7);\n    lightPosYController.setValue(0.7);\n    lightPosZController.setValue(-1.9);\n    lightIntensityController.setValue(5.0);\n  });\n  const lightPosXController = lightFolder\n    .add(settings, 'lightPosX', -5, 5)\n    .step(0.1);\n  const lightPosYController = lightFolder\n    .add(settings, 'lightPosY', -5, 5)\n    .step(0.1);\n  const lightPosZController = lightFolder\n    .add(settings, 'lightPosZ', -5, 5)\n    .step(0.1);\n  const lightIntensityController = lightFolder\n    .add(settings, 'lightIntensity', 0.0, 10)\n    .step(0.1);\n  depthFolder.add(settings, 'depthScale', 0.0, 0.1).step(0.01);\n  depthFolder.add(settings, 'depthLayers', 1, 32).step(1);\n\n  function frame() {\n    if (!pageState.active) return;\n\n    // Update spaceTransformsBuffer\n    const viewMatrix = getViewMatrix();\n    const worldViewMatrix = mat4.mul(viewMatrix, getModelMatrix());\n    const worldViewProjMatrix = mat4.mul(projectionMatrix, worldViewMatrix);\n    const matrices = new Float32Array([\n      ...worldViewProjMatrix,\n      ...worldViewMatrix,\n    ]);\n\n    // Update mapInfoBuffer\n    const lightPosWS = vec3.create(\n      settings.lightPosX,\n      settings.lightPosY,\n      settings.lightPosZ\n    );\n    const lightPosVS = vec3.transformMat4(lightPosWS, viewMatrix);\n    const mode = getMode();\n    device.queue.writeBuffer(\n      spaceTransformsBuffer,\n      0,\n      matrices.buffer,\n      matrices.byteOffset,\n      matrices.byteLength\n    );\n\n    // struct MapInfo {\n    //   lightPosVS: vec3f,\n    //   mode: u32,\n    //   lightIntensity: f32,\n    //   depthScale: f32,\n    //   depthLayers: f32,\n    // }\n    mapInfoView.setFloat32(0, lightPosVS[0], true);\n    mapInfoView.setFloat32(4, lightPosVS[1], true);\n    mapInfoView.setFloat32(8, lightPosVS[2], true);\n    mapInfoView.setUint32(12, mode, true);\n    mapInfoView.setFloat32(16, settings.lightIntensity, true);\n    mapInfoView.setFloat32(20, settings.depthScale, true);\n    mapInfoView.setFloat32(24, settings.depthLayers, true);\n    device.queue.writeBuffer(mapInfoBuffer, 0, mapInfoArray);\n\n    renderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    const commandEncoder = device.createCommandEncoder();\n    const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);\n    // Draw textured Cube\n    passEncoder.setPipeline(texturedCubePipeline);\n    passEncoder.setBindGroup(0, frameBGDescriptor.bindGroups[0]);\n    passEncoder.setBindGroup(\n      1,\n      surfaceBGDescriptor.bindGroups[currentSurfaceBindGroup]\n    );\n    passEncoder.setVertexBuffer(0, box.vertexBuffer);\n    passEncoder.setIndexBuffer(box.indexBuffer, 'uint16');\n    passEncoder.drawIndexed(box.indexCount);\n    passEncoder.end();\n    device.queue.submit([commandEncoder.finish()]);\n\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst NormalMapping: () => JSX.Element = () =>\n  makeSample({\n    name: 'Normal Mapping',\n    description:\n      'This example demonstrates multiple different methods that employ fragment shaders to achieve additional perceptual depth on the surface of a cube mesh. Demonstrated methods include normal mapping, parallax mapping, and steep parallax mapping.',\n    gui: true,\n    init,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: './normalMap.wgsl',\n        contents: normalMapWGSL,\n        editable: true,\n      },\n      {\n        name: '../../meshes/box.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!../../meshes/box.ts').default,\n      },\n      {\n        name: '../../meshes/mesh.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!../../meshes/mesh.ts').default,\n      },\n      {\n        name: './utils.ts',\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        contents: require('!!raw-loader!./utils.ts').default,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default NormalMapping;\n"},{name:"./normalMap.wgsl",contents:s,editable:!0},{name:"../../meshes/box.ts",contents:t(3583).Z},{name:"../../meshes/mesh.ts",contents:t(3150).Z},{name:"./utils.ts",contents:t(1146).Z}],filename:f});var x=h},9147:function(e){e.exports={canvasContainer:"SampleLayout_canvasContainer__zRR_l",sourceFileNav:"SampleLayout_sourceFileNav__ml48P",sourceFileContainer:"SampleLayout_sourceFileContainer__3s84x"}},3583:function(e,n){"use strict";n.Z="import { Mesh } from './mesh';\n\n/**\n * Constructs a box mesh with the given dimensions.\n * The vertex buffer will have the following vertex fields (in the given order):\n *   position  : float32x3\n *   normal    : float32x3\n *   uv        : float32x2\n *   tangent   : float32x3\n *   bitangent : float32x3\n * @param width the width of the box\n * @param height the height of the box\n * @param depth the depth of the box\n * @returns the box mesh with tangent and bitangents.\n */\nexport function createBoxMeshWithTangents(\n  width: number,\n  height: number,\n  depth: number\n): Mesh {\n  //    __________\n  //   /         /|      y\n  //  /   +y    / |      ^\n  // /_________/  |      |\n  // |         |+x|      +---> x\n  // |   +z    |  |     /\n  // |         | /     z\n  // |_________|/\n  //\n  const pX = 0; // +x\n  const nX = 1; // -x\n  const pY = 2; // +y\n  const nY = 3; // -y\n  const pZ = 4; // +z\n  const nZ = 5; // -z\n  const faces = [\n    { tangent: nZ, bitangent: pY, normal: pX },\n    { tangent: pZ, bitangent: pY, normal: nX },\n    { tangent: pX, bitangent: nZ, normal: pY },\n    { tangent: pX, bitangent: pZ, normal: nY },\n    { tangent: pX, bitangent: pY, normal: pZ },\n    { tangent: nX, bitangent: pY, normal: nZ },\n  ];\n  const verticesPerSide = 4;\n  const indicesPerSize = 6;\n  const f32sPerVertex = 14; // position : vec3f, tangent : vec3f, bitangent : vec3f, normal : vec3f, uv :vec2f\n  const vertexStride = f32sPerVertex * 4;\n  const vertices = new Float32Array(\n    faces.length * verticesPerSide * f32sPerVertex\n  );\n  const indices = new Uint16Array(faces.length * indicesPerSize);\n  const halfVecs = [\n    [+width / 2, 0, 0], // +x\n    [-width / 2, 0, 0], // -x\n    [0, +height / 2, 0], // +y\n    [0, -height / 2, 0], // -y\n    [0, 0, +depth / 2], // +z\n    [0, 0, -depth / 2], // -z\n  ];\n\n  let vertexOffset = 0;\n  let indexOffset = 0;\n  for (let faceIndex = 0; faceIndex < faces.length; faceIndex++) {\n    const face = faces[faceIndex];\n    const tangent = halfVecs[face.tangent];\n    const bitangent = halfVecs[face.bitangent];\n    const normal = halfVecs[face.normal];\n\n    for (let u = 0; u < 2; u++) {\n      for (let v = 0; v < 2; v++) {\n        for (let i = 0; i < 3; i++) {\n          vertices[vertexOffset++] =\n            normal[i] +\n            (u == 0 ? -1 : 1) * tangent[i] +\n            (v == 0 ? -1 : 1) * bitangent[i];\n        }\n        for (let i = 0; i < 3; i++) {\n          vertices[vertexOffset++] = normal[i];\n        }\n        vertices[vertexOffset++] = u;\n        vertices[vertexOffset++] = v;\n        for (let i = 0; i < 3; i++) {\n          vertices[vertexOffset++] = tangent[i];\n        }\n        for (let i = 0; i < 3; i++) {\n          vertices[vertexOffset++] = bitangent[i];\n        }\n      }\n    }\n\n    indices[indexOffset++] = faceIndex * verticesPerSide + 0;\n    indices[indexOffset++] = faceIndex * verticesPerSide + 2;\n    indices[indexOffset++] = faceIndex * verticesPerSide + 1;\n\n    indices[indexOffset++] = faceIndex * verticesPerSide + 2;\n    indices[indexOffset++] = faceIndex * verticesPerSide + 3;\n    indices[indexOffset++] = faceIndex * verticesPerSide + 1;\n  }\n\n  return {\n    vertices,\n    indices,\n    vertexStride,\n  };\n}\n"},3150:function(e,n){"use strict";n.Z="import { vec3, vec2 } from 'wgpu-matrix';\n\n// Defines what to pass to pipeline to render mesh\nexport interface Renderable {\n  vertexBuffer: GPUBuffer;\n  indexBuffer: GPUBuffer;\n  indexCount: number;\n  bindGroup?: GPUBindGroup;\n}\n\nexport interface Mesh {\n  vertices: Float32Array;\n  indices: Uint16Array | Uint32Array;\n  vertexStride: number;\n}\n\n/**\n * @param {GPUDevice} device - A valid GPUDevice.\n * @param {Mesh} mesh - An indexed triangle-list mesh, containing its vertices, indices, and vertexStride (number of elements per vertex).\n * @param {boolean} storeVertices - A boolean flag indicating whether the vertexBuffer should be available to use as a storage buffer.\n * @returns {boolean} An object containing an array of bindGroups and the bindGroupLayout they implement.\n */\nexport const createMeshRenderable = (\n  device: GPUDevice,\n  mesh: Mesh,\n  storeVertices = false,\n  storeIndices = false\n): Renderable => {\n  // Define buffer usage\n  const vertexBufferUsage = storeVertices\n    ? GPUBufferUsage.VERTEX | GPUBufferUsage.STORAGE\n    : GPUBufferUsage.VERTEX;\n  const indexBufferUsage = storeIndices\n    ? GPUBufferUsage.INDEX | GPUBufferUsage.STORAGE\n    : GPUBufferUsage.INDEX;\n\n  // Create vertex and index buffers\n  const vertexBuffer = device.createBuffer({\n    size: mesh.vertices.byteLength,\n    usage: vertexBufferUsage,\n    mappedAtCreation: true,\n  });\n  new Float32Array(vertexBuffer.getMappedRange()).set(mesh.vertices);\n  vertexBuffer.unmap();\n\n  const indexBuffer = device.createBuffer({\n    size: mesh.indices.byteLength,\n    usage: indexBufferUsage,\n    mappedAtCreation: true,\n  });\n\n  // Determine whether index buffer is indices are in uint16 or uint32 format\n  if (\n    mesh.indices.byteLength ===\n    mesh.indices.length * Uint16Array.BYTES_PER_ELEMENT\n  ) {\n    new Uint16Array(indexBuffer.getMappedRange()).set(mesh.indices);\n  } else {\n    new Uint32Array(indexBuffer.getMappedRange()).set(mesh.indices);\n  }\n\n  indexBuffer.unmap();\n\n  return {\n    vertexBuffer,\n    indexBuffer,\n    indexCount: mesh.indices.length,\n  };\n};\n\nexport const getMeshPosAtIndex = (mesh: Mesh, index: number) => {\n  const arr = new Float32Array(\n    mesh.vertices.buffer,\n    index * mesh.vertexStride + 0,\n    3\n  );\n  return vec3.fromValues(arr[0], arr[1], arr[2]);\n};\n\nexport const getMeshNormalAtIndex = (mesh: Mesh, index: number) => {\n  const arr = new Float32Array(\n    mesh.vertices.buffer,\n    index * mesh.vertexStride + 3 * Float32Array.BYTES_PER_ELEMENT,\n    3\n  );\n  return vec3.fromValues(arr[0], arr[1], arr[2]);\n};\n\nexport const getMeshUVAtIndex = (mesh: Mesh, index: number) => {\n  const arr = new Float32Array(\n    mesh.vertices.buffer,\n    index * mesh.vertexStride + 6 * Float32Array.BYTES_PER_ELEMENT,\n    2\n  );\n  return vec2.fromValues(arr[0], arr[1]);\n};\n"},1146:function(e,n){"use strict";n.Z="type BindGroupBindingLayout =\n  | GPUBufferBindingLayout\n  | GPUTextureBindingLayout\n  | GPUSamplerBindingLayout\n  | GPUStorageTextureBindingLayout\n  | GPUExternalTextureBindingLayout;\n\nexport type BindGroupsObjectsAndLayout = {\n  bindGroups: GPUBindGroup[];\n  bindGroupLayout: GPUBindGroupLayout;\n};\n\ntype ResourceTypeName =\n  | 'buffer'\n  | 'texture'\n  | 'sampler'\n  | 'externalTexture'\n  | 'storageTexture';\n\n/**\n * @param {number[]} bindings - The binding value of each resource in the bind group.\n * @param {number[]} visibilities - The GPUShaderStage visibility of the resource at the corresponding index.\n * @param {ResourceTypeName[]} resourceTypes - The resourceType at the corresponding index.\n * @returns {BindGroupsObjectsAndLayout} An object containing an array of bindGroups and the bindGroupLayout they implement.\n */\nexport const createBindGroupDescriptor = (\n  bindings: number[],\n  visibilities: number[],\n  resourceTypes: ResourceTypeName[],\n  resourceLayouts: BindGroupBindingLayout[],\n  resources: GPUBindingResource[][],\n  label: string,\n  device: GPUDevice\n): BindGroupsObjectsAndLayout => {\n  // Create layout of each entry within a bindGroup\n  const layoutEntries: GPUBindGroupLayoutEntry[] = [];\n  for (let i = 0; i < bindings.length; i++) {\n    layoutEntries.push({\n      binding: bindings[i],\n      visibility: visibilities[i % visibilities.length],\n      [resourceTypes[i]]: resourceLayouts[i],\n    });\n  }\n\n  // Apply entry layouts to bindGroupLayout\n  const bindGroupLayout = device.createBindGroupLayout({\n    label: `${label}.bindGroupLayout`,\n    entries: layoutEntries,\n  });\n\n  // Create bindGroups that conform to the layout\n  const bindGroups: GPUBindGroup[] = [];\n  for (let i = 0; i < resources.length; i++) {\n    const groupEntries: GPUBindGroupEntry[] = [];\n    for (let j = 0; j < resources[0].length; j++) {\n      groupEntries.push({\n        binding: j,\n        resource: resources[i][j],\n      });\n    }\n    const newBindGroup = device.createBindGroup({\n      label: `${label}.bindGroup${i}`,\n      layout: bindGroupLayout,\n      entries: groupEntries,\n    });\n    bindGroups.push(newBindGroup);\n  }\n\n  return {\n    bindGroups,\n    bindGroupLayout,\n  };\n};\n\nexport type ShaderKeyInterface<T extends string[]> = {\n  [K in T[number]]: number;\n};\n\ninterface AttribAcc {\n  attributes: GPUVertexAttribute[];\n  arrayStride: number;\n}\n\n/**\n * @param {GPUVertexFormat} vf - A valid GPUVertexFormat, representing a per-vertex value that can be passed to the vertex shader.\n * @returns {number} The number of bytes present in the value to be passed.\n */\nexport const convertVertexFormatToBytes = (vf: GPUVertexFormat): number => {\n  const splitFormat = vf.split('x');\n  const bytesPerElement = parseInt(splitFormat[0].replace(/[^0-9]/g, '')) / 8;\n\n  const bytesPerVec =\n    bytesPerElement *\n    (splitFormat[1] !== undefined ? parseInt(splitFormat[1]) : 1);\n\n  return bytesPerVec;\n};\n\n/** Creates a GPUVertexBuffer Layout that maps to an interleaved vertex buffer.\n * @param {GPUVertexFormat[]} vertexFormats - An array of valid GPUVertexFormats.\n * @returns {GPUVertexBufferLayout} A GPUVertexBufferLayout representing an interleaved vertex buffer.\n */\nexport const createVBuffer = (\n  vertexFormats: GPUVertexFormat[]\n): GPUVertexBufferLayout => {\n  const initialValue: AttribAcc = { attributes: [], arrayStride: 0 };\n\n  const vertexBuffer = vertexFormats.reduce(\n    (acc: AttribAcc, curr: GPUVertexFormat, idx: number) => {\n      const newAttribute: GPUVertexAttribute = {\n        shaderLocation: idx,\n        offset: acc.arrayStride,\n        format: curr,\n      };\n      const nextOffset: number =\n        acc.arrayStride + convertVertexFormatToBytes(curr);\n\n      const retVal: AttribAcc = {\n        attributes: [...acc.attributes, newAttribute],\n        arrayStride: nextOffset,\n      };\n      return retVal;\n    },\n    initialValue\n  );\n\n  const layout: GPUVertexBufferLayout = {\n    arrayStride: vertexBuffer.arrayStride,\n    attributes: vertexBuffer.attributes,\n  };\n\n  return layout;\n};\n\nexport const create3DRenderPipeline = (\n  device: GPUDevice,\n  label: string,\n  bgLayouts: GPUBindGroupLayout[],\n  vertexShader: string,\n  vBufferFormats: GPUVertexFormat[],\n  fragmentShader: string,\n  presentationFormat: GPUTextureFormat,\n  depthTest = false,\n  topology: GPUPrimitiveTopology = 'triangle-list',\n  cullMode: GPUCullMode = 'back'\n) => {\n  const pipelineDescriptor: GPURenderPipelineDescriptor = {\n    label: `${label}.pipeline`,\n    layout: device.createPipelineLayout({\n      label: `${label}.pipelineLayout`,\n      bindGroupLayouts: bgLayouts,\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        label: `${label}.vertexShader`,\n        code: vertexShader,\n      }),\n      entryPoint: 'vertexMain',\n      buffers:\n        vBufferFormats.length !== 0 ? [createVBuffer(vBufferFormats)] : [],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        label: `${label}.fragmentShader`,\n        code: fragmentShader,\n      }),\n      entryPoint: 'fragmentMain',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: topology,\n      cullMode: cullMode,\n    },\n  };\n  if (depthTest) {\n    pipelineDescriptor.depthStencil = {\n      depthCompare: 'less',\n      depthWriteEnabled: true,\n      format: 'depth24plus',\n    };\n  }\n  return device.createRenderPipeline(pipelineDescriptor);\n};\n\nexport const createTextureFromImage = (\n  device: GPUDevice,\n  bitmap: ImageBitmap\n) => {\n  const texture: GPUTexture = device.createTexture({\n    size: [bitmap.width, bitmap.height, 1],\n    format: 'rgba8unorm',\n    usage:\n      GPUTextureUsage.TEXTURE_BINDING |\n      GPUTextureUsage.COPY_DST |\n      GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n  device.queue.copyExternalImageToTexture(\n    { source: bitmap },\n    { texture: texture },\n    [bitmap.width, bitmap.height]\n  );\n  return texture;\n};\n"}}]);